{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensors\n",
    "\n",
    "Tensors are THE data structure in machine learning. A tensor is a structure very similar to a numpy array, but it can be used on GPUs. And GPUs we really need if we don't want to get old waiting ..."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basics: initialization, shape, type and device"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialization\n",
    "\n",
    "You can create tensors from numpy arrays and various other data types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the array:  [1 2 3 4 5]\n"
     ]
    }
   ],
   "source": [
    "# create a dummy array\n",
    "import numpy as np\n",
    "example_array = np.array([1, 2, 3, 4, 5])\n",
    "print(\"the array: \", example_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the tensor:  tensor([1, 2, 3, 4, 5])\n"
     ]
    }
   ],
   "source": [
    "# convert the array to a tensor\n",
    "import torch\n",
    "example_tensor = torch.tensor(example_array)\n",
    "print(\"the tensor: \", example_tensor)\n",
    "# there are more functions of how to convert to a tensor\n",
    "# but I like this general one because it is more flexible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1,  6],\n",
       "        [ 2,  7],\n",
       "        [ 3,  8],\n",
       "        [ 4,  9],\n",
       "        [ 5, 10]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# other initialization options\n",
    "# list\n",
    "torch.tensor([1,2,3,4,5])\n",
    "# tuple\n",
    "torch.tensor((1,2,3,4,5))\n",
    "# ranges\n",
    "torch.tensor(range(1,6))\n",
    "# floats and integers\n",
    "torch.tensor(0.5)\n",
    "# dataframes\n",
    "import pandas as pd\n",
    "df = pd.DataFrame({'a': [1,2,3,4,5], 'b': [6,7,8,9,10]})\n",
    "torch.tensor(df.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0.])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# another very helpful one: create an array of zeros (great placeholder)\n",
    "\n",
    "# create an array of 2 zeros\n",
    "torch.zeros(2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More creation options can be found [in the docs](https://pytorch.org/docs/stable/torch.html#creation-ops)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shape, dtype and device\n",
    "\n",
    "A tensor has 3 attributes:\n",
    "- shape\n",
    "- data type\n",
    "- device\n",
    "\n",
    "these words you will often see in error messages, because PyTorch complains about shapes not matching, and data types and devices not being the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the array:  [1 2 3 4 5]\n",
      "with shape:  (5,)\n",
      "and dtype:  int64\n"
     ]
    }
   ],
   "source": [
    "example_array = np.array([1, 2, 3, 4, 5])\n",
    "print(\"the array: \", example_array)\n",
    "print(\"with shape: \", example_array.shape)\n",
    "print(\"and dtype: \", example_array.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "its shape:  torch.Size([5])\n",
      "its dtype:  torch.int64\n",
      "its device:  cpu\n"
     ]
    }
   ],
   "source": [
    "example_tensor = torch.tensor(example_array)\n",
    "print(\"its shape: \", example_tensor.shape)\n",
    "print(\"its dtype: \", example_tensor.dtype)\n",
    "print(\"its device: \", example_tensor.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]])\n",
      "shape:  torch.Size([2, 3])\n"
     ]
    }
   ],
   "source": [
    "# tensors can have as many dimensions as you wish\n",
    "example_tensor = torch.zeros(2, 3)\n",
    "print(example_tensor)\n",
    "print(\"shape: \", example_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "its size (in memory):  8\n",
      "new dtype:  torch.int8\n",
      "new size (in memory):  1\n"
     ]
    }
   ],
   "source": [
    "print(\"its size (in memory): \", example_tensor.element_size()) #returns size in bytes\n",
    "\n",
    "# you can initialize a tensor with a specific dtype\n",
    "example_tensor = torch.tensor(example_array, dtype=torch.int8)\n",
    "print(\"new dtype: \", example_tensor.dtype)\n",
    "print(\"new size (in memory): \", example_tensor.element_size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device available:  cpu\n",
      "device after moving:  cpu\n"
     ]
    }
   ],
   "source": [
    "# the device (where your tensor is stored) is CPU per default\n",
    "# if you have a GPU, you can move your tensor there\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"device available: \", device)\n",
    "example_tensor = example_tensor.to(device)\n",
    "print(\"device after moving: \", example_tensor.device)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensor operations"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Indexing, slicing and concatenating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first row:  tensor([1, 2, 3])\n",
      "first 2 columns:\n",
      " tensor([[1, 2],\n",
      "        [4, 5],\n",
      "        [7, 8]])\n",
      "locations where tensor > 5:\n",
      " tensor([[False, False, False],\n",
      "        [False, False,  True],\n",
      "        [ True,  True,  True]])\n",
      "elements that are > 5 (or elements of the mask locations) tensor([6, 7, 8, 9])\n"
     ]
    }
   ],
   "source": [
    "# create a tensor\n",
    "tensor = torch.tensor([[1, 2, 3],\n",
    "                       [4, 5, 6],\n",
    "                       [7, 8, 9]])\n",
    "\n",
    "# select the first row\n",
    "result1 = tensor[0]\n",
    "\n",
    "# select the first two columns\n",
    "result2 = tensor[:, :2]\n",
    "\n",
    "# select elements with a Boolean mask\n",
    "mask = tensor > 5\n",
    "result3 = tensor[mask] # careful, this is not in the original structure anymore\n",
    "\n",
    "print(\"first row: \", result1)\n",
    "print(\"first 2 columns:\\n\", result2)\n",
    "print(\"locations where tensor > 5:\\n\", mask)\n",
    "print(\"elements that are > 5 (or elements of the mask locations)\", result3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2, 5, 6],\n",
      "        [3, 4, 7, 8]])\n"
     ]
    }
   ],
   "source": [
    "# create two tensors\n",
    "tensor1 = torch.tensor([[1, 2],\n",
    "                        [3, 4]])\n",
    "tensor2 = torch.tensor([[5, 6],\n",
    "                        [7, 8]])\n",
    "\n",
    "# concatenate the two tensors along the second dimension\n",
    "result1 = torch.cat((tensor1, tensor2), dim=1)\n",
    "\n",
    "print(result1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More options can be found [in the docs](https://pytorch.org/docs/stable/torch.html#indexing-slicing-joining-mutating-ops)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Element-wise operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2, 3],\n",
      "        [5, 6]])\n"
     ]
    }
   ],
   "source": [
    "# create two tensors\n",
    "tensor1 = torch.tensor([[1, 1],\n",
    "                        [2, 2]])\n",
    "tensor2 = torch.tensor([[1, 2],\n",
    "                        [3, 4]])\n",
    "\n",
    "# add the two tensors element-wise\n",
    "result = torch.add(tensor1, tensor2)\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These special element-wise operations give the same results as classic math operations (see below). However, using them instead of math operations can be more efficient. For small tensors, you don't have to worry about this though ;)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2, 3],\n",
      "        [5, 6]])\n"
     ]
    }
   ],
   "source": [
    "# add the two tensors element-wise\n",
    "result = tensor1 + tensor2\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More options can be found [in the docs](https://pytorch.org/docs/stable/torch.html#pointwise-ops)\n",
    "\n",
    "Some useful examples are\n",
    "- sub\n",
    "- mul\n",
    "- div\n",
    "- pow\n",
    "- exp\n",
    "- log"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reduction operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2],\n",
      "        [3, 4]])\n",
      "tensor([4, 6])\n"
     ]
    }
   ],
   "source": [
    "# create a tensor\n",
    "tensor = torch.tensor([[1, 2],\n",
    "                       [3, 4]])\n",
    "print(tensor)\n",
    "\n",
    "# sum the tensor along the first dimension\n",
    "result = torch.sum(tensor, dim=0)\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More options can be found [in the docs](https://pytorch.org/docs/stable/torch.html#reduction-ops)\n",
    "\n",
    "Some useful examples are\n",
    "- mean\n",
    "- min\n",
    "- std\n",
    "- count_nonzero\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matrix operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 4,  6],\n",
      "        [ 8, 12]])\n"
     ]
    }
   ],
   "source": [
    "# create two matrices as tensors\n",
    "matrix1 = torch.tensor([[1, 1],\n",
    "                        [2, 2]])\n",
    "matrix2 = torch.tensor([[1, 2],\n",
    "                        [3, 4]])\n",
    "\n",
    "# multiply the two matrices\n",
    "result = torch.matmul(matrix1, matrix2)\n",
    "# does [[m1(0,0)*m2(0,0) + m1(0,1)*m2(1,0)], [m1(1,0)*m2(0,0) + m1(1,1)*m2(1,0)]]\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More options can be found [in the docs](https://pytorch.org/docs/stable/torch.html#blas-and-lapack-operations)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More advanced stuff\n",
    "\n",
    "Here are some -in my opinion- importent behaviours of tensors I wish I had known earlier, but they are not necessary to get started in Pytorch. Let's see how it goes in the course up until here. Otherwise, feel free to have a look yourselves."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Broadcasting\n",
    "\n",
    "Broadcasting is a PyTorch feature that enables you to perform element-wise operations on tensors with different shapes. In my opinion, this is one of the most useful but hidden features of torch.\n",
    "The rules about broadcasting are:\n",
    "- If two tensors have the same number of dimensions, their shapes must either be equal or one of them must be 1 in all dimensions.\n",
    "- If two tensors have different numbers of dimensions, the tensor with fewer dimensions is expanded by adding dimensions of size 1 on the left until the number of dimensions matches.\n",
    "\n",
    "Here is a figure demonstrating the rules:\n",
    "\n",
    "<img src=\"../images/tensor_broadcasting.png\" width=\"300\">\n",
    "\n",
    "So let's have a look at the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2, 4, 6],\n",
      "        [5, 7, 9]])\n"
     ]
    }
   ],
   "source": [
    "# tensor with shape (2, 3)\n",
    "tensor1 = torch.tensor([[1, 2, 3],\n",
    "                        [4, 5, 6]])\n",
    "# tensor with shape (3,)\n",
    "tensor2 = torch.tensor([1, 2, 3])\n",
    "result = tensor1 + tensor2\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (3) must match the size of tensor b (2) at non-singleton dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[61], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[39m# tensor with shape (2,)\u001b[39;00m\n\u001b[1;32m      6\u001b[0m tensor2 \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtensor([\u001b[39m1\u001b[39m, \u001b[39m2\u001b[39m])\n\u001b[0;32m----> 8\u001b[0m result \u001b[39m=\u001b[39m tensor1 \u001b[39m+\u001b[39;49m tensor2\n\u001b[1;32m     10\u001b[0m \u001b[39mprint\u001b[39m(result)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (3) must match the size of tensor b (2) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "# tensor with shape (2, 3)\n",
    "tensor1 = torch.tensor([[1, 2, 3],\n",
    "                        [4, 5, 6]])\n",
    "# tensor with shape (2,)\n",
    "tensor2 = torch.tensor([1, 2])\n",
    "result = tensor1 + tensor2\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2, 3, 4],\n",
      "        [6, 7, 8]])\n"
     ]
    }
   ],
   "source": [
    "# tensor with shape (2, 3)\n",
    "tensor1 = torch.tensor([[1, 2, 3],\n",
    "                        [4, 5, 6]])\n",
    "# tensor with shape (2, 1)\n",
    "tensor2 = torch.tensor([1, 2]).unsqueeze(1)\n",
    "result = tensor1 + tensor2\n",
    "print(result)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensor modification\n",
    "\n",
    "As briefly shown, we can change the dimensions and shapes of tensors as we please."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can add and remove dimensions:\n",
    "- tensor.<span style=\"color:slateblue\">squeeze</span>() reduces a given dimension\n",
    "- tensor.<span style=\"color:slateblue\">unsqueeze</span>() adds a dimension in a given position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original shape:\n",
      "    torch.Size([2, 3])\n",
      "unsqueezing the first dimension:\n",
      "    torch.Size([1, 2, 3])\n",
      "unsqueezing the second dimension:\n",
      "    torch.Size([2, 1, 3])\n",
      "unsqueezing the last dimension:\n",
      "    torch.Size([2, 3, 1])\n"
     ]
    }
   ],
   "source": [
    "tensor1 = torch.tensor([[1, 2, 3],\n",
    "                        [4, 5, 6]])\n",
    "\n",
    "print(\"original shape:\\n   \", tensor1.shape)\n",
    "print(\"unsqueezing the first dimension:\\n   \", tensor1.unsqueeze(0).shape)\n",
    "print(\"unsqueezing the second dimension:\\n   \", tensor1.unsqueeze(1).shape)\n",
    "print(\"unsqueezing the last dimension:\\n   \", tensor1.unsqueeze(-1).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of squeezed tensor:\n",
      "    torch.Size([2, 3])\n",
      "new tensor of shape:\n",
      "    torch.Size([1, 3])\n",
      "shape of the squeezed new tensor:\n",
      "    torch.Size([3])\n"
     ]
    }
   ],
   "source": [
    "# what can we squeeze?\n",
    "\n",
    "# if the dimension to be squeezed is larger than 1, nothing happens\n",
    "print(\"shape of squeezed tensor:\\n   \", tensor1.squeeze(0).shape)\n",
    "\n",
    "tensor2 = torch.tensor([[1, 2, 3]])\n",
    "print(\"new tensor of shape:\\n   \", tensor2.shape)\n",
    "print(\"shape of the squeezed new tensor:\\n   \", tensor2.squeeze(0).shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also change the shapes completely\n",
    "- tensor.<span style=\"color:slateblue\">view</span>()\n",
    "- tensor.<span style=\"color:slateblue\">expand</span>()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can understand viewing and reshaping as taking the tensor's values in their natural occurance, that means our tensor\n",
    "\n",
    "| | c1 | c2 | c3 |\n",
    "| --- | :---: | :---: | :---: |\n",
    "| r1 | 1 | 2 | 3 |\n",
    "| r2 | 4 | 5 | 6 |\n",
    "\n",
    "Is first going by row, then by column. The order of elements can be seen by flattening the tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3, 4, 5, 6])\n"
     ]
    }
   ],
   "source": [
    "tensor1 = torch.tensor([[1, 2, 3],\n",
    "                        [4, 5, 6]])\n",
    "print(tensor1.flatten())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When using view, the tensor elements are sorted into the new defined shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2],\n",
      "        [3, 4],\n",
      "        [5, 6]])\n"
     ]
    }
   ],
   "source": [
    "print(tensor1.view(3,2))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I can also let torch do some of the thinking for me. If I have a 2d tensor, I only have to specify the new size of one dimension, the other one will be defined `automatically`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2],\n",
      "        [3, 4],\n",
      "        [5, 6]])\n"
     ]
    }
   ],
   "source": [
    "print(tensor1.view(-1,2))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So what are these reshaped tensors?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "memory address of tensor1:\n",
      " 0x7f7b8b56cf40\n",
      "memory address of tensor2:\n",
      " 0x7f7b8b56cf40\n"
     ]
    }
   ],
   "source": [
    "print(\"memory address of tensor1:\\n\",hex(tensor1.storage().data_ptr()))\n",
    "\n",
    "tensor2 = tensor1.view(-1)\n",
    "\n",
    "print(\"memory address of tensor2:\\n\",hex(tensor2.storage().data_ptr()))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See that tensor1 and tensor2 have the same memory address?\n",
    "The view is not creating a new tensor, but just a different `view` on the same tensor. We call tensor2 a `pointer`. If you want this as a new and independent tensor, make a copy of unsing tensor.<span style=\"color:slateblue\">clone</span>()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "memory address of tensor2:\n",
      " 0x7f7b8b572a40\n"
     ]
    }
   ],
   "source": [
    "tensor2 = tensor1.clone().view(-1,2)\n",
    "print(\"memory address of tensor2:\\n\",hex(tensor2.storage().data_ptr()))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you don't just need a new view, but for some reason you need to make the tensor bigger in some dimension, you can use tensor.<span style=\"color:slateblue\">expand</span>()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original tensor size:\n",
      " torch.Size([1, 3])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3],\n",
       "        [1, 2, 3]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor3 = torch.tensor([[1, 2, 3]])\n",
    "print(\"original tensor size:\\n\", tensor3.shape)\n",
    "\n",
    "# expanding the tensor in dimension 0 (first dimension), keeping the other dimension the same\n",
    "tensor3.expand(2, -1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
